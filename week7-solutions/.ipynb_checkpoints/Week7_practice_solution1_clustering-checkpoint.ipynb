{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 7 Practice Solution 1: Clustering on Handwritten Digits\n",
        "\n",
        "**Dataset**: Digits (64 features, 1797 samples, 10 digit classes)\n",
        "\n",
        "We use clustering **without labels** to discover natural groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "digits = datasets.load_digits()\n",
        "X = digits.data\n",
        "y_true = digits.target  # Only for later comparison, not for clustering\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "print('Digits dataset shape:', X.shape)\n",
        "print('Features (pixels):', n_features)\n",
        "print('Unique true labels (digits 0-9):', len(np.unique(y_true)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Standardize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print('Standardized: mean ≈ 0, std ≈ 1')\n",
        "print('Mean (first 5 features):', X_scaled[:, :5].mean(axis=0).round(4))\n",
        "print('Std  (first 5 features):', X_scaled[:, :5].std(axis=0).round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Choose Number of Clusters: Elbow and Silhouette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K_range = range(2, 16)\n",
        "inertias = []\n",
        "silhouettes = []\n",
        "\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = km.fit_predict(X_scaled)\n",
        "    inertias.append(km.inertia_)\n",
        "    silhouettes.append(silhouette_score(X_scaled, labels))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(K_range, inertias, 'bo-')\n",
        "axes[0].set_xlabel('Number of clusters (k)')\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].set_title('Elbow Method')\n",
        "axes[0].set_xticks(K_range)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(K_range, silhouettes, 'go-')\n",
        "axes[1].set_xlabel('Number of clusters (k)')\n",
        "axes[1].set_ylabel('Silhouette Score')\n",
        "axes[1].set_title('Silhouette Score (higher = better)')\n",
        "axes[1].set_xticks(K_range)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "best_k_sil = list(K_range)[np.argmax(silhouettes)]\n",
        "print(f'Best k by silhouette: {best_k_sil}')\n",
        "print('We use k=10 for comparison with true 10 digits; elbow is gradual so k=10 is reasonable.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. K-Means with k=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 10\n",
        "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "centers_scaled = kmeans.cluster_centers_\n",
        "centers_original = scaler.inverse_transform(centers_scaled)\n",
        "\n",
        "print('K-Means cluster sizes:')\n",
        "for i in range(k):\n",
        "    print(f'  Cluster {i}: {(kmeans_labels == i).sum()} samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D plot: use first two features (or first two PCs for better separation)\n",
        "from sklearn.decomposition import PCA\n",
        "pca_vis = PCA(n_components=2)\n",
        "X_2d = pca_vis.fit_transform(X_scaled)\n",
        "centers_2d = pca_vis.transform(centers_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans_labels, cmap='tab10', s=15, alpha=0.6)\n",
        "plt.scatter(centers_2d[:, 0], centers_2d[:, 1], c='black', marker='X', s=200, linewidths=2, label='Centroids')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('K-Means Clustering (k=10) in 2D PCA space')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hierarchical Clustering and Dendrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = 100\n",
        "idx = np.random.choice(X_scaled.shape[0], sample_size, replace=False)\n",
        "X_sample = X_scaled[idx]\n",
        "\n",
        "linkage_matrix = linkage(X_sample, method='ward')\n",
        "plt.figure(figsize=(14, 6))\n",
        "dendrogram(linkage_matrix, leaf_rotation=90, leaf_font_size=8)\n",
        "plt.title('Dendrogram (Ward, sample of 100)')\n",
        "plt.xlabel('Sample index')\n",
        "plt.ylabel('Distance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hier = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
        "hier_labels = hier.fit_predict(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=hier_labels, cmap='tab10', s=15, alpha=0.6)\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Hierarchical Clustering (k=10, Ward) in 2D PCA space')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare K-Means vs Hierarchical (and True Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "axes[0].scatter(X_2d[:, 0], X_2d[:, 1], c=y_true, cmap='tab10', s=15, alpha=0.6)\n",
        "axes[0].set_title('True labels (digits 0-9)')\n",
        "axes[0].set_xlabel('PC1')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans_labels, cmap='tab10', s=15, alpha=0.6)\n",
        "axes[1].set_title('K-Means (k=10)')\n",
        "axes[1].set_xlabel('PC1')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].scatter(X_2d[:, 0], X_2d[:, 1], c=hier_labels, cmap='tab10', s=15, alpha=0.6)\n",
        "axes[2].set_title('Hierarchical (k=10)')\n",
        "axes[2].set_xlabel('PC1')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ari_kmeans = adjusted_rand_score(y_true, kmeans_labels)\n",
        "ari_hier = adjusted_rand_score(y_true, hier_labels)\n",
        "print(f'Adjusted Rand Index (vs true labels): K-Means = {ari_kmeans:.4f}, Hierarchical = {ari_hier:.4f}')\n",
        "print('(ARI in [0,1]; higher means clusters agree more with true classes.)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "- **Choice of k**: Elbow is gradual for digits; silhouette often peaks around k=9–10. Using k=10 matches the number of digit classes.\n",
        "- **K-Means vs Hierarchical**: Both produce plausible segmentations; ARI shows how much each agrees with true digits (without using labels during clustering).\n",
        "- **Takeaway**: On this 64-dimensional data, standardizing and using 2D PCA for visualization helps compare methods; clusters often partially align with digit identity."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
